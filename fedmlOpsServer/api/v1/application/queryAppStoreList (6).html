{"message":"Succeeded to process
request","code":"SUCCESS","data":{"total":4,"totalPage":1,"pageNum":1,"pageSize":16,"data":[{"id":1346,"versionId":5563,"owner":"Flux","applicationName":"Schnell","jobType":2,"jobSubType":null,"accessPermission":0,"pictureUrl":"https://fedml.s3.us-west-1.amazonaws.com/1725404183163Screenshot%202024-08-27%20at%204.52.13%E2%80%AFPM.png","description":"#
Flux Schnell, powered by TensorOpera
AI","modelId":1,"dataId":1,"platformId":-1,"users":0,"favorites":0,"views":267,"requests":"1314","sort":null,"version":"v5-Wed
Aug 28 00:53:21 GMT 2024","tags":["Text to
Image"],"playground":false,"createTime":"2024-08-28T00:53:25","updateBy":"Flux","updateTime":"2024-09-03T22:58:32"},{"id":1141,"versionId":5527,"owner":"Qualcomm","applicationName":"SDXL","jobType":2,"jobSubType":null,"accessPermission":0,"pictureUrl":"https://fedml.s3.us-west-1.amazonaws.com/1715821105178SDXLQ2.png","description":"Get
started today by visiting
[https://TensorOpera.ai/qualcomm-cloud-ai-100](https://tensoropera.ai/qualcomm-cloud-ai-100)
to apply for early access to *Qualcomm-TensorOpera* dedicated or serverless
model
endpoints.\n\n---\n\n![https://fedml.s3.us-west-1.amazonaws.com/1715822335208high_quality_sdxl.png](https://fedml.s3.us-west-1.amazonaws.com/1715822335208high_quality_sdxl.png)","modelId":1,"dataId":1,"platformId":-1,"users":0,"favorites":4,"views":450,"requests":"472","sort":null,"version":"v8-Thu
Aug 08 05:22:48 GMT 2024","tags":["Text to
Image"],"playground":false,"createTime":"2024-08-08T17:31:20","updateBy":"Qualcomm","updateTime":"2024-08-21T17:55:04"},{"id":914,"versionId":5457,"owner":"latent-consistency","applicationName":"stable-diffusion-xl-base","jobType":2,"jobSubType":null,"accessPermission":0,"pictureUrl":"https://fedml.s3.us-west-1.amazonaws.com/1710457787795sdxl%2Bcoverimage%2Bmilkyweights.png","description":"The
Stability AI team is proud to release as an open model SDXL 1.0, the next
iteration in the evolution of text-to-image generation models. Following the
limited, research-only release of SDXL 0.9, the full version of SDXL has been
improved to be the world's best open image generation
model.\n\n![](https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/eba39670-66c6-4921-bdb9-19dce66f0a46/sdxl+coverimage+milkyweights.png)\n\nSDXL
1.0 launch, made with forthcoming image control from Stability AI.\n\n####
\\*\\*The best image model from Stability AI\\*\\*\n\nSDXL 1.0 is the flagship
image model from Stability AI and the best open model for image generation.
We’ve tested it against various other models, and the results are conclusive -
people prefer images generated by SDXL 1.0 over other open models. This research
results from weeks of preference data captured from generations of experimental
models on our Discord and from external
testing.\n\n![](https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/3a90a864-2b38-4a44-8645-2ae827a095e3/SDXL+preference+graph.png)\n\n####
\\*\\*Better artwork for challenging concepts and styles\\*\\*\n\nSDXL generates
images of high quality in virtually any art style and is the best open model for
photorealism. Distinct images can be prompted without having any particular
‘feel’ imparted by the model, ensuring absolute freedom of style. SDXL 1.0 is
particularly well-tuned for vibrant and accurate colors, with better contrast,
lighting, and shadows than its predecessor, all in native 1024x1024
resolution.\n\nIn addition, SDXL can generate concepts that are notoriously
difficult for image models to render, such as hands and text or spatially
arranged compositions (e.g., a woman in the background chasing a dog in the
foreground).\n\n![](https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/cc1b0eab-ed11-4af9-bde5-f62bbc3b728d/sdxl\\_horizontal3.png)\n\nBetter
spatial configuration and style control, including photorealism.\n\n####
\\*\\*More intelligent with simpler language\\*\\*\n\nSDXL requires only a few
words to create complex, detailed, and aesthetically pleasing images. Users no
longer need to invoke qualifier terms like “masterpiece” to get high-quality
images. Furthermore, SDXL can understand the differences between concepts like
“The Red Square” (a famous place) vs a “red square” (a
shape).\n\n![](https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/c6d4be29-8502-402b-8ccc-1a5f28d59fe2/sdxl\\_horizontal2.png)\n\nSimple
prompts, quality outputs.\n\n#### \\*\\*The largest open image
model\\*\\*\n\nSDXL 1.0 has one of the largest parameter counts of any open
access image model, boasting a 3.5B parameter base model and a 6.6B parameter
model ensemble pipeline (the final output is created by running on two models
and aggregating the results).\n\nThe full model consists of a mixture-of-experts
pipeline for latent diffusion: In the first step, the base model generates
(noisy) latents, which are then further processed with a refinement model
specialized for the final denoising steps. Note that the base model can also be
used as a standalone module.\n\nThis two-stage architecture allows for
robustness in image generation without compromising on speed or requiring excess
compute resources. SDXL 1.0 should work effectively on consumer GPUs with 8GB
VRAM or readily available cloud
instances.\n\n![](https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/8305f97c-e950-4220-8e68-67d00b7191a6/SDXL+steps.png)\n\n####
\\*\\*Fine-tuning and advanced control\\*\\*\n\nWith SDXL 1.0, fine-tuning the
model to custom data is easier than ever. Custom LoRAs or checkpoints can be
generated with less need for data wrangling. The Stability AI team is building
the next generation of task-specific structure, style, and composition controls,
with T2I / ControlNet specialized for SDXL. These features are currently in beta
preview but stay tuned for updates on fine-tuning.\n\nImage control on SDXL is
forthcoming.\n\n[View fullsize![sdxl
finetune1.png](https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/1690394463107-TKH7OQD7LWEAJPZP0Z79/sdxl+finetune1.png?format=1500w)](https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/1690394463107-TKH7OQD7LWEAJPZP0Z79/sdxl+finetune1.png)\n\n[View
fullsize![sdxl
finetune2.png](https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/1690394463181-LKEL1Y9INROK0ZAL9R6O/sdxl+finetune2.png?format=1500w)](https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/1690394463181-LKEL1Y9INROK0ZAL9R6O/sdxl+finetune2.png)\n\n[View
fullsize![sdxl
finetune3.png](https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/1690394464324-KRKL9I42OPPD9ADA011V/sdxl+finetune3.png?format=1500w)](https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/1690394464324-KRKL9I42OPPD9ADA011V/sdxl+finetune3.png)\n\n[View
fullsize![sdxl
finetune4.png](https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/1690394464914-W4UZHH4GC8YDJACA0YHZ/sdxl+finetune4.png?format=1500w)](https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/1690394464914-W4UZHH4GC8YDJACA0YHZ/sdxl+finetune4.png)","modelId":1,"dataId":1,"platformId":-1,"users":0,"favorites":2,"views":617,"requests":"114","sort":null,"version":"v7-Fri
Mar 22 01:01:54 GMT 2024","tags":["Text to
Image"],"playground":false,"createTime":"2024-06-29T01:38:41","updateBy":"latent-consistency","updateTime":"2024-06-29T01:38:51"},{"id":687,"versionId":4014,"owner":"latent-consistency","applicationName":"lcm-lora-sdv1-5","jobType":2,"jobSubType":null,"accessPermission":0,"pictureUrl":"https://fedml.s3.us-west-1.amazonaws.com/1708128534372Latent.webp","description":"##
Introduction\n\nLatent Consistency Model (LCM) LoRA was proposed in
[LCM-LoRA](https://arxiv.org/abs/2311.05556): A universal Stable-Diffusion
Acceleration Module by Simian Luo, Yiqin Tan, Suraj Patil, Daniel Gu et
al.\n\nIt is a distilled consistency adapter for
[runwayml/stable-diffusion-v1-5](https://huggingface.co/runwayml/stable-diffusion-v1-5)
that allows to reduce the number of inference steps to only between 2 - 8
steps.\n\n| Model | Params / M |\n|-----------------|------------|\n|
lcm-lora-sdv1-5 | 67.5 |\n| lcm-lora-ssd-1b | 105 |\n| lcm-lora-sdxl | 197
|\n\n## Text-to-Image\n\nThe adapter can be loaded with SDv1-5 or deviratives.
Here we use [Lykon/dreamshaper-7](https://huggingface.co/Lykon/dreamshaper-7).
Next, the scheduler has changed to LCMScheduler and we can reduce the number of
inference steps to just 2 to 8 steps. We also disable guidance_scale.\n\nNote:
For detailed usage examples we recommend you to check out the official
[LCM-LoRA](https://huggingface.co/docs/diffusers/main/en/using-diffusers/inference_with_lcm_lora)
docs.","modelId":1,"dataId":1,"platformId":-1,"users":0,"favorites":0,"views":69,"requests":"0","sort":null,"version":"v1-Sat
Feb 17 00:09:28 GMT 2024","tags":["Text to
Image"],"playground":false,"createTime":"2024-02-22T19:11:40","updateBy":"latent-consistency","updateTime":"2024-02-22T19:11:45"}]}}
